{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1068fba4-da5d-42b5-980b-0c274d73f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from deepgram import Deepgram\n",
    "\n",
    "# brew install portaudio\n",
    "os.chdir(\"..\")\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set your Deepgram API Key and desired voice model\n",
    "DG_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "MODEL_NAME =\"aura-asteria-en\"  # Example model name, change as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43de53fc-a994-4d38-8e50-877d6eee9b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not open socket: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_transcript\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/official/medbot-deepgram/env/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from deepgram import (\n",
    "    DeepgramClient,\n",
    "    DeepgramClientOptions,\n",
    "    LiveTranscriptionEvents,\n",
    "    LiveOptions,\n",
    "    Microphone,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class TranscriptCollector:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.transcript_parts = []\n",
    "\n",
    "    def add_part(self, part):\n",
    "        self.transcript_parts.append(part)\n",
    "\n",
    "    def get_full_transcript(self):\n",
    "        return ' '.join(self.transcript_parts)\n",
    "\n",
    "transcript_collector = TranscriptCollector()\n",
    "\n",
    "async def get_transcript():\n",
    "    try:\n",
    "        config = DeepgramClientOptions(options={\"keepalive\": \"true\"})\n",
    "        deepgram: DeepgramClient = DeepgramClient(\"\", config)\n",
    "\n",
    "        dg_connection = deepgram.listen.asynclive.v(\"1\")\n",
    "\n",
    "        async def on_message(self, result, **kwargs):\n",
    "            # print (result)\n",
    "            sentence = result.channel.alternatives[0].transcript\n",
    "\n",
    "            print(\"part sen:\",sentence)\n",
    "            \n",
    "            if not result.speech_final:\n",
    "                transcript_collector.add_part(sentence)\n",
    "            else:\n",
    "                # This is the final part of the current sentence\n",
    "                transcript_collector.add_part(sentence)\n",
    "                full_sentence = transcript_collector.get_full_transcript()\n",
    "                print(f\"speaker: {full_sentence}\")\n",
    "                # Reset the collector for the next sentence\n",
    "                transcript_collector.reset()\n",
    "\n",
    "        async def on_error(self, error, **kwargs):\n",
    "            print(f\"\\n\\n{error}\\n\\n\")\n",
    "\n",
    "        dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)\n",
    "        dg_connection.on(LiveTranscriptionEvents.Error, on_error)\n",
    "\n",
    "        options = LiveOptions(\n",
    "            model=\"nova-2\",\n",
    "            punctuate=True,\n",
    "            language=\"en-US\",\n",
    "            encoding=\"linear16\",\n",
    "            channels=1,\n",
    "            sample_rate=16000,\n",
    "            # Time in milliseconds of silence to wait for before finalizing speech\n",
    "\n",
    "            endpointing=300,\n",
    "            # To get UtteranceEnd, the following must be set:\n",
    "            interim_results=True,\n",
    "            utterance_end_ms=\"1000\",\n",
    "            vad_events=True,\n",
    "        )\n",
    "\n",
    "        await dg_connection.start(options)\n",
    "\n",
    "        # Open a microphone stream on the default input device\n",
    "        microphone = Microphone(dg_connection.send)\n",
    "\n",
    "        # start microphone\n",
    "        microphone.start()\n",
    "\n",
    "        while True:\n",
    "            if not microphone.is_active():\n",
    "                break\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "        # Wait for the microphone to close\n",
    "        microphone.finish()\n",
    "\n",
    "        # Indicate that we've finished\n",
    "        dg_connection.finish()\n",
    "\n",
    "        print(\"Finished\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open socket: {e}\")\n",
    "        return\n",
    "\n",
    "asyncio.run(get_transcript())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d22b65-a799-40ae-9caa-c61106b21980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
